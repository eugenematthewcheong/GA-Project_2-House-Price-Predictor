{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 2: Kaggle Submission\n",
    "\n",
    "> Authors: Lim Zheng Gang, Eugene Matthew Cheong, Pius Yee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook 4. Kaggle Submission\n",
    "##### In this Notebook 4, we will apply the same data cleaning and feature engineering techniques used on the training data to the test dataset. This will ensure consistency and allow us to generate model results suitable for Kaggle submission.\n",
    "\n",
    "##### We will proceed to Kaggle submission once generated the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeating the same data cleaning and feature engineering on the test dataset as below:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from datetime import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file\n",
    "hdb_raw = pd.read_csv(\"../datasets/test.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(lat1, lng1, lat2, lng2):\n",
    "    # Your distance calculation function (you can use haversine or any other)\n",
    "    # Example using haversine formula:\n",
    "    R = 6371  # Earth radius in kilometers\n",
    "    dlat = np.radians(lat2 - lat1)\n",
    "    dlng = np.radians(lng2 - lng1)\n",
    "    a = np.sin(dlat / 2) * np.sin(dlat / 2) + np.cos(np.radians(lat1)) * np.cos(np.radians(lat2)) * np.sin(dlng / 2) * np.sin(dlng / 2)\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    distance_km = R * c\n",
    "    return distance_km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up data and remove null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to replace said columns with 0\n",
    "\n",
    "hdb_raw[\"Mall_Within_500m\"] = hdb_raw[\"Mall_Within_500m\"].map(lambda x : 0 if np.isnan(x) else x)\n",
    "hdb_raw[\"Mall_Within_1km\"] = hdb_raw[\"Mall_Within_1km\"].map(lambda x : 0 if np.isnan(x) else x)\n",
    "hdb_raw[\"Mall_Within_2km\"] = hdb_raw[\"Mall_Within_2km\"].map(lambda x : 0 if np.isnan(x) else x) \n",
    "hdb_raw[\"Hawker_Within_500m\"] = hdb_raw[\"Hawker_Within_500m\"].map(lambda x : 0 if np.isnan(x) else x)\n",
    "hdb_raw[\"Hawker_Within_1km\"] = hdb_raw[\"Hawker_Within_1km\"].map(lambda x : 0 if np.isnan(x) else x)\n",
    "hdb_raw[\"Hawker_Within_2km\"] = hdb_raw[\"Hawker_Within_2km\"].map(lambda x : 0 if np.isnan(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "col_Y_N = ['commercial','market_hawker','multistorey_carpark','precinct_pavilion']\n",
    "\n",
    "for col in col_Y_N:\n",
    "    hdb_raw[col] = hdb_raw[col].str.replace('N','0')\n",
    "    hdb_raw[col] = hdb_raw[col].str.replace('Y','1').astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdb_raw[\"tenure\"] = hdb_raw[\"Tranc_Year\"] - hdb_raw[\"lease_commence_date\"]\n",
    "bin_edges = list(range(0, hdb_raw[\"tenure\"].max() + 6, 5))\n",
    "bin_edges = [0,11, hdb_raw[\"tenure\"].max() + 1]\n",
    "bin_labels = [f\"{bin_edges[i]}-{bin_edges[i+1]-1}\" for i in range(len(bin_edges)-1)]\n",
    "hdb_raw[\"tenure_buckets\"] = pd.cut(hdb_raw[\"tenure\"], bins=bin_edges, labels=bin_labels, include_lowest=True, right=False)\n",
    "hdb_raw = pd.get_dummies(hdb_raw, columns=['tenure_buckets'], prefix='tenure_buckets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distance from centre - choose 79 Anson Road (1.2742738490494008, 103.84567324086873)\n",
    "\n",
    "lat1 = 1.2742738490494008\n",
    "lng1 =  103.84567324086873\n",
    "hdb_raw[\"from_centre_distance\"] = calculate_distance(lat1, lng1, hdb_raw[\"Latitude\"], hdb_raw[\"Longitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdb_raw[\"is_pre_war\"] = hdb_raw[\"year_completed\"].map(lambda x : 1 if x == 1949 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_sm_location = pd.read_csv(\"../datasets/sm_location_supermalls.csv\")\n",
    "\n",
    "df_mh_calculation = pd.DataFrame()\n",
    "df_mh_calculation[\"id\"] = hdb_raw[\"id\"]\n",
    "df_mh_calculation[\"lat\"] = hdb_raw[\"Latitude\"]\n",
    "df_mh_calculation[\"lng\"] = hdb_raw[\"Longitude\"]\n",
    "\n",
    "for each_id in df_mh_calculation[\"id\"].values:\n",
    "    lat1 = df_mh_calculation.loc[df_mh_calculation[df_mh_calculation[\"id\"]==each_id].index, \"lat\"].iloc[0]\n",
    "    lng1 = df_mh_calculation.loc[df_mh_calculation[df_mh_calculation[\"id\"]==each_id].index, \"lng\"].iloc[0]\n",
    "\n",
    "    latitudes = df_sm_location[\"LATITUDE\"].values\n",
    "    longitudes = df_sm_location[\"LONGITUDE\"].values\n",
    "\n",
    "    distances = calculate_distance(lat1, lng1, latitudes, longitudes)\n",
    "\n",
    "    min_dist_mall = np.min(distances)\n",
    "\n",
    "    df_mh_calculation.loc[df_mh_calculation[df_mh_calculation[\"id\"]==each_id].index, \"mh\"] = min_dist_mall\n",
    "    \n",
    "df_mh_calculation.to_csv('../datasets/supermh_test.csv', index=False) # to avoid running above loop again\n",
    "hdb_raw = pd.merge(hdb_raw, df_mh_calculation[['id', 'mh']], on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdb_raw[\"is_premium\"] = hdb_raw[\"flat_model\"].map(lambda x: 1 if x in  (\"Improved-Maisonette\",\"DBSS\") else 0)\n",
    "hdb_raw[\"is_terrace\"] = hdb_raw[\"flat_model\"].map(lambda x: 1 if x ==  \"Terrace\" else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdb_raw[\"is_superlargeterrace\"] = hdb_raw[\"floor_area_sqft\"].map(lambda x: 1 if x >= 2250 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new column for mature/non mature estate\n",
    "mature_lst = [\"Ang Mo Kio\",\"Bedok\",\"Bishan\",\"Bukit Merah\",\"Bukit Timah\",\"Clementi\",\"Downtown Core\",\"Geylang\",\"Kallang\",\"Marine Parade\", \"Novena\", \"Outram\", \"Pasir Ris\", \"Queenstown\", \"Rochor\",\"Serangoon\",\"Tampines\",\"Tanglin\",\"Toa Payoh\"]\n",
    "area_category_mapping = {\n",
    "    'Tanglin': \"Group1\",\n",
    "    'Bukit Timah': \"Group1\",\n",
    "    'Outram': \"Group1\",\n",
    "    'Downtown Core': \"Group1\",\n",
    "    'Bishan': \"Group1\",\n",
    "    'Bukit Merah': \"GroupJB\",\n",
    "    'Queenstown': \"GroupCQS\",\n",
    "    'Marine Parade': \"GroupCM\",\n",
    "    'Serangoon': \"GroupCQS\",\n",
    "    'Clementi': \"GroupCQS\",\n",
    "    'Hougang': \"GroupYH\",\n",
    "    'Bukit Panjang': \"GroupPWC\",\n",
    "    'Western Water Catchment': \"Group2\",\n",
    "    'Jurong East': \"GroupJB\",\n",
    "    'Ang Mo Kio': \"GroupA\",\n",
    "    'Choa Chu Kang': \"GroupPWC\",\n",
    "    'Woodlands': \"GroupPWC\",\n",
    "    'Yishun': \"GroupYH\",\n",
    "    'Changi': \"GroupCM\"\n",
    "}\n",
    "\n",
    "hdb_raw[\"mature\"] = hdb_raw[\"planning_area\"].apply(lambda x: 1 if x in mature_lst else 0)\n",
    "hdb_raw['planning_area_category'] = hdb_raw['planning_area'].map(area_category_mapping)\n",
    "hdb_raw = pd.get_dummies(hdb_raw, columns=['planning_area_category'], prefix='planning_area_category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_category_mapping = {\n",
    "    2014: \"Group2\",\n",
    "    2015: \"Group1\",\n",
    "    2016: \"Group1\",\n",
    "    2017: \"Group2\",\n",
    "    2018: \"Group1\",\n",
    "    2019: \"Group0\",\n",
    "    2020: \"Group2\",\n",
    "\n",
    "}\n",
    "\n",
    "hdb_raw['year_category'] = hdb_raw['Tranc_Year'].map(year_category_mapping)\n",
    "hdb_raw = pd.get_dummies(hdb_raw, columns=['year_category'], prefix='year_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify boolean columns\n",
    "bool_columns = hdb_raw.select_dtypes(include='bool').columns\n",
    "\n",
    "# Convert boolean columns to int\n",
    "hdb_raw[bool_columns] = hdb_raw[bool_columns].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdb_raw = pd.get_dummies(hdb_raw, columns=['flat_type'], prefix='flat_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    \"Tranc_YearMonth\", \"town\", \"block\", \"price_per_sqft\", \"street_name\", \"storey_range\", \"floor_area_sqm\", \n",
    "    \"mid_storey\", \"lower\", \"full_flat_type\", \"address\", \"residential\", \"1room_rental\", \"2room_rental\", \n",
    "    \"3room_rental\", \"other_room_rental\", \"postal\", \"mrt_name\", \"mrt_latitude\", \"mrt_longitude\", \n",
    "    \"bus_stop_name\", \"bus_stop_latitude\", \"bus_stop_longitude\", \"pri_sch_name\", \"pri_sch_latitude\", \n",
    "    \"pri_sch_longitude\", \"sec_sch_name\", \"sec_sch_latitude\", \"sec_sch_longitude\", 'multistorey_carpark', \n",
    "    'precinct_pavilion', 'hawker_food_stalls', 'hawker_market_stalls', 'bus_interchange', 'cutoff_point', \n",
    "    'vacancy', 'flat_model', 'planning_area', 'lease_commence_date', 'Tranc_Year', 'Tranc_Month', 'upper', 'hdb_age', 'year_completed', 'commercial', 'market_hawker', \n",
    "    'total_dwelling_units', '1room_sold', '2room_sold', '3room_sold', '4room_sold', '5room_sold', \n",
    "    'exec_sold', 'multigen_sold', 'studio_apartment_sold', 'Latitude', 'Longitude', 'Mall_Nearest_Distance', \n",
    "    'Mall_Within_500m', 'Mall_Within_1km', 'Mall_Within_2km', 'Hawker_Nearest_Distance', 'Hawker_Within_500m', \n",
    "    'Hawker_Within_1km', 'Hawker_Within_2km', 'bus_stop_nearest_distance', 'pri_sch_nearest_distance', \n",
    "    'pri_sch_affiliation', 'sec_sch_nearest_dist', 'affiliation', 'tenure_buckets_11-54', 'flat_type_4 ROOM', 'flat_type_5 ROOM', \n",
    "    'flat_type_EXECUTIVE', 'flat_type_MULTI-GENERATION','flat_type_3 ROOM', 'mrt_interchange', 'planning_area_category_Group2'\n",
    "]\n",
    "\n",
    "\n",
    "hdb_cleaned = hdb_raw.drop(columns = columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'mid', 'floor_area_sqft', 'max_floor_lvl', 'mrt_nearest_distance',\n",
       "       'tenure', 'tenure_buckets_0-10', 'from_centre_distance', 'is_pre_war',\n",
       "       'mh', 'is_premium', 'is_terrace', 'is_superlargeterrace', 'mature',\n",
       "       'planning_area_category_Group1', 'planning_area_category_GroupA',\n",
       "       'planning_area_category_GroupCM', 'planning_area_category_GroupCQS',\n",
       "       'planning_area_category_GroupJB', 'planning_area_category_GroupPWC',\n",
       "       'planning_area_category_GroupYH', 'year_category_Group0',\n",
       "       'year_category_Group1', 'year_category_Group2', 'flat_type_1 ROOM',\n",
       "       'flat_type_2 ROOM'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdb_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hdb_cleaned.loc[:, [ 'mid', 'floor_area_sqft', 'max_floor_lvl',\n",
    "       'mrt_nearest_distance', 'mature', 'planning_area_category_Group1',\n",
    "       'planning_area_category_GroupA', 'planning_area_category_GroupCM',\n",
    "       'planning_area_category_GroupCQS', 'planning_area_category_GroupJB',\n",
    "       'planning_area_category_GroupPWC', 'planning_area_category_GroupYH',\n",
    "       'tenure', 'tenure_buckets_0-10', 'year_category_Group0',\n",
    "       'year_category_Group1', 'year_category_Group2', 'is_premium',\n",
    "       'is_terrace', 'is_superlargeterrace', 'flat_type_1 ROOM',\n",
    "       'flat_type_2 ROOM', 'is_pre_war', 'from_centre_distance', 'mh']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/lasso.pkl', 'rb') as handle:\n",
    "    lasso_cv = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "y_pred = lasso_cv.predict(X_scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16737,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdb_cleaned[\"id\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_adjust = np.exp(y_pred)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_pred_adjust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "\n",
    "submission[\"Id\"] = hdb_cleaned[\"id\"]\n",
    "submission[\"Predicted\"] = y_pred_adjust\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export the Kaggle submission CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('../datasets/submission_kaggle.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle submission done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/submission.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
